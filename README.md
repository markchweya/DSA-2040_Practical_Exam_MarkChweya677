
---

# DSA 2040 US 2025 End Semester Practical Exam – Mark Chweya (ID: 677)

## 📌 Overview

This repository contains my complete submission for the **DSA 2040 US 2025 End Semester Practical Exam**.
It covers **Data Warehousing** (Section 1) and **Data Mining** (Section 2) tasks as outlined in the exam paper.
All work is implemented in **Python** with supporting **SQL scripts**, **visualizations**, and **reports**.

---

## 📂 Repository Structure

```
├── DSA_2040_Practical_Exam.ipynb     # Main Jupyter Notebook with all code & markdown explanations
├── retail_dw.db                      # SQLite database generated by ETL
├── star_schema.png                   # Star schema diagram
├── sales_by_country_quarter.png      # OLAP Roll-up visualization
├── iris_pairplot.png                 # Iris dataset pairplot
├── iris_heatmap.png                  # Iris feature correlation heatmap
├── iris_boxplots.png                 # Iris feature boxplots
├── kmeans_elbow_curve.png            # Elbow curve for K-Means
├── kmeans_clusters.png               # Cluster visualization
├── decision_tree_visualization.png   # Decision tree diagram
├── association_rules.csv             # Extracted top 5 association rules
├── README.md                         # This file
```

---

## 📊 Datasets Used

### **Section 1 – Data Warehousing**

* **Synthetic Online Retail dataset** generated using Python and Faker library.
* 1,000 transactions across 5 countries, 100 unique customers, and 8 products in 3 categories.
* Stored in `retail_dw.db` as:

  * `CustomerDim`
  * `ProductDim`
  * `TimeDim`
  * `SalesFact`

### **Section 2 – Data Mining**

* **Iris dataset** from scikit-learn.
* Preprocessed: handled missing values, scaled features with Min-Max, encoded target labels.

---

## ▶️ Run Instructions

1. Clone this repository:

   ```bash
   git clone https://github.com/<your-username>/DSA_2040_Practical_Exam_MarkChweya677.git
   cd DSA_2040_Practical_Exam_MarkChweya677
   ```
2. Install required Python libraries:

   ```bash
   pip install pandas numpy matplotlib seaborn scikit-learn faker mlxtend
   ```
3. Open the notebook:

   ```bash
   jupyter notebook DSA_2040_Practical_Exam.ipynb
   ```
4. Run all cells in order to:

   * Generate synthetic retail data
   * Perform ETL into SQLite
   * Run OLAP queries & visualizations
   * Preprocess and explore Iris dataset
   * Perform clustering, classification, and association rule mining

---

## 📝 Self-Assessment

* **Section 1 – Data Warehousing (50 marks)**

  * ✅ Star schema diagram created and explained.
  * ✅ ETL pipeline implemented with synthetic dataset.
  * ✅ OLAP queries executed with visualization and analysis report.
* **Section 2 – Data Mining (50 marks)**

  * ✅ Data preprocessing & exploration completed.
  * ✅ K-Means clustering (k=2, 3, 4) with ARI, elbow curve, scatter plot.
  * ✅ Decision Tree and KNN classification with performance comparison.
  * ✅ Association rule mining with top 5 rules and retail implications.
* **Challenges:**

  * Had to generate synthetic datasets to match exam requirements.
  * Managed transformations to maintain data integrity for both sections.
* **Confidence:** The notebook runs end-to-end without errors and covers all exam tasks as described.

---


